API

Split API into two levels?
- low-level API with sort of Turing power
- high-level API that give examples how use the low-level API. Could be only
  static inlines.


* clarify the API to obtain the number of nodes, procs, cores, ...
* Drop ignore_threads and explain how to deal with cores/sockets with singlify

* cache or node specific functions?
  + get nodes covering a cpuset?
  + get shared cache*S* covering a cpuset?

* topomask: add an option to request a cpuset containing of n close entries
  among the generated cpuset

* have an easy way to get a valid full set (alias on get_machine_object()->cpuset) ?

* expose the internal conversion from cpuset to sched_setaffinity mask?
  + reverse routine?

Doc
===
* complete doc

Support
=======
* add support for amd magny-cours "multi-node-cpu", probably by reading 
  cpu_node_siblings/id if available (in 2.6.31+).
  should look like multiple sockets in single numa node?
  but looks like their L3s are hardware-merged

* there could be several size for huge pages

* add some padding in the object attributes so that we can add new stuff
  without breaking the ABI?
  + for instance if we move dmi info in the machine attributes
  + for instance if we add the cache type
  + or make attribute a pointer?  (ST: I'd vote for that)

* integrate marcel split quirk?
  + split for real, just explain how to split?
    - just return an ordered array?

* use topology_allocator for real, including in strdup
  + add topo_set_allocator() to be called before _init()

* Kerrighed: Use
int migrate (pid_t pid, int destination_node);
int migrate_self (int destination_node);
int thread_migrate (int thread_id, int destination_node);

* move dmi_* to a machine object?

* add a lstopo-output-reading backend

* lstopo-nox
  + disable xml as well?

Binding
=======
* topo_set_cpubind(pid, ...) which type for pid? POSIX says that pid_t is a
  signed integer type
* topo_set_cpubind for threads, pb: depending on the OS, the function takes a
  pthread_t or a kernel tid.
* topo_set_membind()
  + reverse routine?
  + no level = empty mask, and we may want an easy alias for "whole machine"

* make them do nothing if passed a fake topology?
  + so applications can just always call them and still have synthetic tests.

Binding tool for OAR, MPI, Hydra, MPI+OpenMP:
* topo_taskset --ncpus 2 --near 3
  bind process on 2 cores near physical proc id 3
* topo_taskset --index 4
  bind process on 4th processor in a topology-aware numbering
* topo_taskset --ncpus 2 --index 4
  bind process on the 4th set of 2 physically close ids in a topology-aware numbering (used by ggrun when launching 4 process with 2 threads)
* tools to create masks and bind using them
